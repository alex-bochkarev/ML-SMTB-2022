{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef12cae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Course title](./images/title.png)\n",
    "<i> Alexey Bochkarev </i> | [üåê www.bochkarev.io](https://www.bochkarev.io) | [‚úâ a@bochkarev.io](mailto:a@bochkarev.io)\n",
    "\n",
    "**Discord:** `co05-–∫–∞–∫-—É—á–∏—Ç—å-–º–∞—à–∏–Ω—ã-–ø—Ä–æ—Å—Ç—ã–µ-–ø—Ä–∏–º–µ—Ä—ã-–ø—Ä–æ-ml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eef565",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# ‚ë¢ Neural Networks: Image Recognition!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8a2234",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First: we will use `PyTorch`, a popular ML framework. That will make things way easier (and remove the necessity to take derivatives by hand :))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389c3bdb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2778326c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There is an overhead cost though: we will need to load data with a somewhat unusual way (with this `DataLoader` class defined in `torch.utils.data`. On the positive side: MNIST dataset is so popular that PyTorch will download it for us automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086707e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Convert input images to tensors and normalize\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# Get the MNIST data from torchvision\n",
    "dataset1 = datasets.MNIST('./', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('./', train=False,\n",
    "                    transform=transform)\n",
    "\n",
    "# Define the data loaders that will handle fetching of data\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size = 64)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, batch_size = 14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc777c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see what data we have (\"eyeballing\" the data is always a good thing to do!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a23a3557",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439401a1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "018ca99a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQmUlEQVR4nO3df0yUeX4H8LeAd1flFFZxJgcWPaK3uGvCZDvUFu25d0al/4CXaNQ2kqw3mo3UmpAGapPOJZummMbQ3a5n4uwY8VZq3BICNSGOi3sJsXs62uGXiyINEn44M6xExeRyCnz7h1n2XJnvg8/zzA/5vF8JCcxnvvN8fOJ7npnnO898FwBQIKJ5Ly3ZDRBRYjDsREIw7ERCMOxEQjDsREJkJHJjD6OPEBkcS+QmiURx5Ocga8XSWWuWwr5t2zZ8+OGHSE9PxyeffIJjx45p7x8ZHMOh4hormyQijRPXa2PWTL+MT0tLw4kTJ1BaWop169Zhz549KCwsNPtwRBRnpsNeXFyM/v5+DAwM4NmzZzh//jzKysrs7I2IbGQ67Lm5uRgaGpr5e3h4GLm5uS/dz+PxIBgMIhgMYmnOErObIyKL4n423ufzwe12w+1249HY43hvjohiMB32kZERrFy5cubvvLw8jIyM2NIUEdnPdNiDwSDWrFmDVatWYeHChdi9ezdaWlrs7I2IbGR66m1qagqVlZW4dOkS0tPTcfr0aXz11Vd29kZENrI0z97a2orW1la7eiGiOOLHZYmEYNiJhGDYiYRg2ImEYNiJhGDYiYRg2ImEYNiJhGDYiYRg2ImEYNiJhGDYiYRg2ImEYNiJhGDYiYRg2ImEYNiJhGDYiYRg2ImEYNiJhGDYiYRg2ImEYNiJhGDYiYRg2ImEYNiJhGDYiYRg2ImEYNiJhLC0iivZI33dWm399vvZ2nrasj+Y3vadn57W1qehtPV3u3dq67rRkfEl2rFGCv59Sn+H692WHn++sRT2gYEBTExMYGpqCpOTk3C73Xb1RUQ2s3xkf/fdd/HgwQM7eiGiOOJ7diIhLIVdKYVAIIAbN27A4/HMeh+Px4NgMIhgMIilOdbeoxGReZZexm/cuBGjo6PIycnB5cuXcfv2bbS3t79wH5/PB5/PBwC4E+y3sjkissDSkX10dBQAMDY2hqamJhQXF9vSFBHZz3TYFy1ahMzMzJnft27dip6eHtsaIyJ7mX4Z73A40NTU9PxBMjLQ0NCAS5cu2dbY6yRjZZ62nv7ppLZ+dOV/auuu709r62ma5+xp6MdOGzzfG43/Yv1npsfr+p7Lti/+2TJt/fTPNsWsTQ6PaMfOR6bDPjAwgKKiIhtbIaJ44tQbkRAMO5EQDDuREAw7kRAMO5EQvMTVBn99qVNbP7D0nraehgXautH0mH68lbHxHW912+WLH2rro5dif+7j4lv6y4bnIx7ZiYRg2ImEYNiJhGDYiYRg2ImEYNiJhGDYiYTgPLsNjObRjS7VNHrOtTL+r7p2aUeOWfw6578vuqKtH8jSfTtR/P7dRtu+WPye/qHn4ddQ88hOJATDTiQEw04kBMNOJATDTiQEw04kBMNOJATn2W2QzGvCAcAbdcWsLSn9P+1YqwtyXYT+uvCLSNWVfeffPLoRHtmJhGDYiYRg2ImEYNiJhGDYiYRg2ImEYNiJhOA8uw2moQzq8b6enciY4ZHd7/cjEomgu/vbDyFkZ2cjEAigr68PgUAAWVlZ8eyRiGxgGPYzZ85g+/btL9xWU1ODtrY2rF27Fm1tbaipqYlbg0RkD8Owt7e3Y3x8/IXbysrKUF9fDwCor69HeXl5XJojIvuYes/ucDgQDocBAOFwGA6HI+Z9PR4PDhw4AABYmmP1k9hEZJYtZ+OVin2Cyufzwe12w+1249HYYzs2R0QmmAp7JBKB0+kEADidTkSjUVubIiL7mQp7S0sLKioqAAAVFRVobm62tSkisp/he/aGhgZs3rwZy5cvx9DQELxeL2pra3HhwgXs378fg4OD2LVL/93k812yr2f/YEVHzNr0iP4zAMZrw+vHv9u9U1v/Yv1nprf964ertfU/X6T7TnrgyD/+XczaD8//Tjt2PjIM+969e2e9fcuWLbY3Q0Txw4/LEgnBsBMJwbATCcGwEwnBsBMJwUtcbZD8S1xjj4/3tnVTa8bjzS+5/Hy0fvwXx/8jZq1k8WHt2GX+L7X11xGP7ERCMOxEQjDsREIw7ERCMOxEQjDsREIw7ERCcJ7dBsm+xFU/Pr7bDj3Vz8O7vhd7fGTq99qxv37wl9q67tLe52Jv+9FP9COXGTzy64hHdiIhGHYiIRh2IiEYdiIhGHYiIRh2IiEYdiIhOM9ug1S+nv3EwwLtyIuVPzN4bL3vhSe09afOH8asZTx5ph2rgt3autHXZOv2W9vuf9OO/bn6B239x9Wv3/XuPLITCcGwEwnBsBMJwbATCcGwEwnBsBMJwbATCcF5dhuUbyjT1tM/ndTW314yqq3/9723tfUf/Wt67OJ1/Vx1Ov5XWzcyZVBP741d08+SG7NyLX5u+iLtyN/s/Fhb91a/Y7Dt1GN4ZPf7/YhEIuju/vY/jdfrxfDwMEKhEEKhEEpLS+PaJBFZZxj2M2fOYPv27S/dXldXB5fLBZfLhdbW1rg0R0T2MQx7e3s7xsfHE9ELEcWR6RN0lZWV6OzshN/vR1ZWVsz7eTweBINBBINBLM1ZYnZzRGSRqbCfPHkSBQUFKCoqwv3793H8+PGY9/X5fHC73XC73Xg09th0o0RkjamwR6NRTE9PQykFn8+H4uJiu/siIpuZCrvT6Zz5fceOHejp6bGtISKKD8N59oaGBmzevBnLly/H0NAQvF4vNm/ejKKiIiilcO/ePRw8eDARvaasyaFhff2n+vE3DZ5zf4SvXrWl+aF4vbY8jZsGdfNrw//tl7/U1gsQ0tZTkWHY9+7d+9Jtp0+fjkszRBQ//LgskRAMO5EQDDuREAw7kRAMO5EQvMSVkiZ93Vpt/Z/Pn9HWrVziajR21SdGj/364ZGdSAiGnUgIhp1ICIadSAiGnUgIhp1ICIadSAjOs1PS3H4/W1t3fV+/VPW0paWu5R3n5P2LiYRi2ImEYNiJhGDYiYRg2ImEYNiJhGDYiYTgPDtZkp61VFu//cGbMWt3f3FSO9ZoHj2e17PPRzyyEwnBsBMJwbATCcGwEwnBsBMJwbATCcGwEwnBefYEeLD/L7T1Rz/Rj//xfz3R3+F69yt2NHdGvf9gZ0Rb713/ccyatevRAaNj1YmHBTFrH7Vt045982avtj6lraYmwyN7Xl4erly5glu3bqGnpweHDx8GAGRnZyMQCKCvrw+BQABZWVnx7pWILDAM++TkJKqqqvDWW29hw4YNOHToEAoLC1FTU4O2tjasXbsWbW1tqKmpSUS/RGSSYdjD4TBCoRAA4MmTJ+jt7UVubi7KyspQX18PAKivr0d5eXlcGyUia17pPXt+fj5cLheuXbsGh8OBcDgM4PkTgsPhmHWMx+PBgQMHAABLc5ZYbJeIzJrz2fjFixejsbERR44cwcTExEt1pdSs43w+H9xuN9xuNx6NPTbfKRFZMqewZ2RkoLGxEefOnUNTUxMAIBKJwOl0AgCcTiei0Wj8uiQiy+b0Mt7v96O3txd1dXUzt7W0tKCiogLHjh1DRUUFmpub49ZkqjNaevjjf4o9/QQAG36Qrq0/+xv9RI/ucs1pzP6Kay5jn4+/aXG8lctMrV3iqpteW3P4mnbs6zi1ZsQw7CUlJdi3bx+6urpmTtQdPXoUtbW1uHDhAvbv34/BwUHs2rUr7s0SkXmGYb969SoWLJj9GXTLli22N0RE8cGPyxIJwbATCcGwEwnBsBMJwbATCcFLXO0wHNaWq/p2auu/Xf+Ztm7lUk+rl4nGd7y1bd/8g378myfHY9bm4zy6ER7ZiYRg2ImEYNiJhGDYiYRg2ImEYNiJhGDYiYTgPLsNph7rv4Enc7u+/vOy97X1jb/6nbb+wYoOTTV+yx7PZbxuLrzyXyq1Y5f5v9TWjd21OH5+4ZGdSAiGnUgIhp1ICIadSAiGnUgIhp1ICIadSAjOs6eAP2m+rq133lyprb/9y40xa8/W/N5UT9/YVNBvaXzHp+tj1lb4/8fSY9Or4ZGdSAiGnUgIhp1ICIadSAiGnUgIhp1ICIadSAjDefa8vDycPXsWDocDSimcOnUKH330EbxeLzweD8bGxgA8X8a5tbU17g1LNDk8oq3/6a/0dStGLY5fAc6lpwrDsE9OTqKqqgqhUAiZmZm4efMmLl++DACoq6vD8ePH494kEVlnGPZwOIxw+PmKJ0+ePEFvby9yc3Pj3hgR2euV3rPn5+fD5XLh2rVrAIDKykp0dnbC7/cjKytr1jEejwfBYBDBYBBLc5ZYbpiIzJlz2BcvXozGxkYcOXIEExMTOHnyJAoKClBUVIT79+/HfDnv8/ngdrvhdrvxaEz/XWxEFD9zCntGRgYaGxtx7tw5NDU1AQCi0Simp6ehlILP50NxcXFcGyUia+YUdr/fj97eXtTV1c3c5nQ6Z37fsWMHenp67O+OiGxjeIKupKQE+/btQ1dXF0KhEIDn02x79uxBUVERlFK4d+8eDh48GPdmicg8w7BfvXoVCxa8/N3gnFMner3wE3REQjDsREIw7ERCMOxEQjDsREIw7ERCMOxEQjDsREIw7ERCMOxEQjDsREIw7ERCMOxEQjDsREIsAKAStbFoNIrBwcGZv5cvX46vv/46UZt/JanaW6r2BbA3s+zsLT8/HytWrIhZV8n6CQaDSdv269pbqvbF3lK/N76MJxKCYScSIqlhP3XqVDI3r5WqvaVqXwB7MytRvSX0BB0RJQ9fxhMJwbATCZGUsG/btg23b9/G3bt3UV1dnYwWYhoYGJj5jvxgMJjUXvx+PyKRCLq7u2duy87ORiAQQF9fHwKBQMw19pLRm9frxfDwMEKhEEKhEEpLS5PSW15eHq5cuYJbt26hp6cHhw8fBpD8fRerr0Tut4TOKaalpan+/n61evVqtXDhQtXR0aEKCwuTPtf5zc/AwIBatmxZ0vsAoDZt2qRcLpfq7u6eue3YsWOqurpaAVDV1dWqtrY2ZXrzer2qqqoq6fvN6XQql8ulAKjMzEx1584dVVhYmPR9F6uvRO23hB/Zi4uL0d/fj4GBATx79gznz59HWVlZott4LbS3t2N8fPyF28rKylBfXw8AqK+vR3l5eRI6m723VBEOh2dWL/rjZcaTve9i9ZUoCQ97bm4uhoaGZv4eHh5OqfXelVIIBAK4ceMGPB5Pstt5icPhQDgcBvD8P4/D4UhyRy+ayzLeifTHy4yn0r4zs/y5VTxB9x0bN27EO++8g9LSUhw6dAibNm1KdktaSqlktzBjrst4J8p3lxn/rmTtO7PLn1uV8LCPjIxg5cqVM3/n5eVhZGQk0W3ENDo6CgAYGxtDU1NTyi1FHYlEZlbQdTqdiEajSe7oW6m0jPdsy4ynwr5L5vLnCQ97MBjEmjVrsGrVKixcuBC7d+9GS0tLotuY1aJFi5CZmTnz+9atW1NuKeqWlhZUVFQAACoqKtDc3Jzkjr6VSst4z7bMeCrsu2Qvf57ws6WlpaXqzp07qr+/Xx09ejTpZ2+/+Vm9erXq6OhQHR0dqqenJ+m9NTQ0qNHRUfX06VM1NDSk3nvvPfXGG2+ozz//XPX19anLly+r7OzslOnt7NmzqqurS3V2dqrm5mbldDqT0ltJSYlSSqnOzk4VCoVUKBRSpaWlSd93sfpK1H7jx2WJhOAJOiIhGHYiIRh2IiEYdiIhGHYiIRh2IiEYdiIh/h/bBy7SJPvqDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Re-run this cell several times to\n",
    "# check out different numbers!\n",
    "\n",
    "m = np.random.randint(1, 1000)\n",
    "\n",
    "img = dataset1[m][0]\n",
    "lbl = dataset1[m][1]\n",
    "\n",
    "plt.imshow(img[0])\n",
    "print(f\"Correct label: {lbl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ff540",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let us define a simple model.\n",
    "\n",
    "We will use more or less the same type of \"perceptrons\" we had before, but we will add layers. That is:\n",
    "\n",
    "![NN architecture](./images/mnist-net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e78de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In PyTorch speak this will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31460300",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(64, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69870c44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Now, fix a few parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2215f9b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # Somewhat in the similar logic like we had for Logit\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Optimization method\n",
    "batch_size = 128\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a808ebe2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd01aeca",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Note that I have also saved the model with:\n",
    "# torch.save(model, \"./MNIST_model.pt\")\n",
    "# (so you could try to load it instead of training for 2 hours...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92dc3e0b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] Loss: 2128.369\n",
      "Epoch [10] Loss: 389.390\n",
      "Epoch [20] Loss: 272.579\n",
      "Epoch [30] Loss: 217.342\n",
      "Epoch [40] Loss: 177.566\n",
      "Epoch [50] Loss: 147.899\n",
      "Epoch [60] Loss: 125.352\n",
      "Epoch [70] Loss: 107.727\n",
      "Epoch [80] Loss: 93.621\n",
      "Epoch [90] Loss: 82.114\n",
      "Epoch [100] Loss: 72.551\n",
      "Epoch [110] Loss: 64.461\n",
      "Epoch [120] Loss: 57.515\n",
      "Epoch [130] Loss: 51.484\n",
      "Epoch [140] Loss: 46.202\n",
      "Epoch [150] Loss: 41.548\n",
      "Epoch [160] Loss: 37.429\n",
      "Epoch [170] Loss: 33.775\n",
      "Epoch [180] Loss: 30.531\n",
      "Epoch [190] Loss: 27.649\n",
      "Epoch [200] Loss: 25.088\n",
      "Epoch [210] Loss: 22.811\n",
      "Epoch [220] Loss: 20.783\n",
      "Epoch [230] Loss: 18.977\n",
      "Epoch [240] Loss: 17.366\n",
      "Epoch [250] Loss: 15.928\n",
      "Epoch [260] Loss: 14.645\n",
      "Epoch [270] Loss: 13.499\n",
      "Epoch [280] Loss: 12.474\n",
      "Epoch [290] Loss: 11.556\n",
      "Epoch [300] Loss: 10.732\n",
      "Epoch [310] Loss: 9.991\n",
      "Epoch [320] Loss: 9.322\n",
      "Epoch [330] Loss: 8.717\n",
      "Epoch [340] Loss: 8.168\n",
      "Epoch [350] Loss: 7.668\n",
      "Epoch [360] Loss: 7.212\n",
      "Epoch [370] Loss: 6.794\n",
      "Epoch [380] Loss: 6.411\n",
      "Epoch [390] Loss: 6.059\n",
      "Epoch [400] Loss: 5.735\n",
      "Epoch [410] Loss: 5.436\n",
      "Epoch [420] Loss: 5.160\n",
      "Epoch [430] Loss: 4.904\n",
      "Epoch [440] Loss: 4.668\n",
      "Epoch [450] Loss: 4.448\n",
      "Epoch [460] Loss: 4.245\n",
      "Epoch [470] Loss: 4.057\n",
      "Epoch [480] Loss: 3.882\n",
      "Epoch [490] Loss: 3.720\n",
      "\n",
      " ### Finished Training in 110.4 min ### \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (batch_data, target) in enumerate(train_loader):\n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        batch_data = batch_data.view(batch_data.size(0), -1)\n",
    "        pred_labels = model(batch_data)  # forward pass\n",
    "        \n",
    "        loss = criterion(pred_labels, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print progress\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [{epoch}] Loss: {running_loss:.3f}\")\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "print (f\"\\n ### Finished Training in {(t1-t0)/60:.1f} min ### \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ebccfe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's test what we have got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bce1e080",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct label: 4\n",
      "Prediction: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAP6ElEQVR4nO3df2zU933H8Zd/NSlYYCd27lqbASWwOukku9m52QwraRHgqq1BmhCgDk+gA2kwSmVpdtgf/qNbBZuQl2wpEhczzIRFqTzP7jSLI0adXLLSIzobmxgcb8byrzubsIEJS4Lt7/5gdUvwfQ/ut/15PiRL9vd93+/nra948b37fu7ukybJEoAFLz3ZDQBIDMIOGIKwA4Yg7IAhCDtgiMxEDvY/43cUHJxI5JCAURzL85XzwtI5a1GFfdOmTXrjjTeUkZGht99+W0ePHrV9fHBwQvtLa6IZEoCNt351JGQt4qfx6enpeuutt1ReXq6XXnpJO3bsUFFRUaSHAxBnEYe9tLRU/f39GhgY0IMHD3T27FlVVFTEsjcAMRRx2AsKCjQ0NDT79/DwsAoKCh57nNvtls/nk8/n09L8JZEOByBKcb8b7/F45HK55HK5dGfibryHAxBCxGEfGRnRsmXLZv8uLCzUyMhITJoCEHsRh93n82n16tVasWKFsrKytH37drW2tsayNwAxFPHU2/T0tA4cOKDz588rIyNDJ0+e1Pvvvx/L3gDEUFTz7G1tbWpra4tVLwDiiLfLAoYg7IAhCDtgCMIOGIKwA4Yg7IAhCDtgCMIOGIKwA4Yg7IAhCDtgCMIOGIKwA4Yg7IAhCDtgCMIOGIKwA4Yg7IAhCDtgCMIOGIKwA4Yg7IAhCDtgCMIOGIKwA4Yg7IAhCDtgCMIOGIKwA4aIahVXzH9WWbFt/fDp07b13f+617a++vu/fNqWECdRhX1gYECTk5Oanp7W1NSUXC5XrPoCEGNRX9lfe+01ffjhh7HoBUAc8ZodMERUYbcsS16vV1euXJHb7Z7zMW63Wz6fTz6fT0vzl0QzHIAoRPU0fu3atRodHVV+fr4uXLig69evq6Oj45HHeDweeTweSdINX380wwGIQlRX9tHRUUnSxMSEmpubVVpaGpOmAMRexGFftGiRsrOzZ3/fuHGjenp6YtYYgNiK+Gm8w+FQc3Pzw4NkZqqxsVHnz5+PWWOIjfTFi23rP2g4Y1tf9+yUbT3NeuqWkCQRh31gYEDFxcUxbAVAPDH1BhiCsAOGIOyAIQg7YAjCDhiCj7gucPdfe9m2/s3Pd9jWw3nualpU+yNxuLIDhiDsgCEIO2AIwg4YgrADhiDsgCEIO2AI5tkXgIy850PWCl7/IKpjHx7/qm0976f232EwE9XoiCWu7IAhCDtgCMIOGIKwA4Yg7IAhCDtgCMIOGIJ59gVgvGJNyNrPVrxlu2/fg49t67/40dds69mTl23rqerTzfYrDo+us4/Gqro+2/r0rdRb7JQrO2AIwg4YgrADhiDsgCEIO2AIwg4YgrADhmCefT5Iz7AtO//kZsSH/vYv9tvWX/zp/JxHl6TgwT8MWWuu+hvbfb+Y+Yxt/bstu+0Hn4/z7PX19QoGg+ru7p7dlpubK6/Xq76+Pnm9XuXk5MSzRwAxEDbsp06d0ubNmx/ZVlNTo/b2dq1Zs0bt7e2qqamJW4MAYiNs2Ds6OnT79u1HtlVUVKihoUGS1NDQoC1btsSlOQCxE9FrdofDoUAgIEkKBAJyOBwhH+t2u7V3715J0tL8JZEMByAGYnI33rKskDWPxyOXyyWXy6U7E3djMRyACEQU9mAwKKfTKUlyOp0aHx+PaVMAYi+isLe2tqqyslKSVFlZqZaWlpg2BSD2wr5mb2xs1Pr165WXl6ehoSHV1tbqyJEjOnfunPbs2aPBwUFt27YtEb0a6/6W37et/3z18ZC1sen7tvu++D1/RD2lguHXQ8+jS9KZvXUha89l2L93oeTH37etL/vVu7b1VBQ27Dt37pxz+4YNG2LeDID44e2ygCEIO2AIwg4YgrADhiDsgCH4iOs8MPbHn0S87ybfPtt6oa5FfOx4C/65/dTa6b1/Z1v/vc9lhaxVDn7Ddt9lfz3/ptbC4coOGIKwA4Yg7IAhCDtgCMIOGIKwA4Yg7IAhmGdf4H7nh6G/RUiSZuI8flrW50LWhqvCfHR3/9/a1nPTP29brwqUhqzd/q79R1wXIq7sgCEIO2AIwg4YgrADhiDsgCEIO2AIwg4Ygnn2BS7to4/jevxPvuWyrS+pHgpZ63rxH8Ic3X4effUFt2296PWRkLXpW4EwYy88XNkBQxB2wBCEHTAEYQcMQdgBQxB2wBCEHTAE8+wLXP8Ps23r6X1/YFv/zrd/aVuvfeHvbevZ6c+GrE3bf9ReX3m30rZe9JdjtvWpMfPm0u2EvbLX19crGAyqu7t7dlttba2Gh4fl9/vl9/tVXl4e1yYBRC9s2E+dOqXNmzc/tr2urk4lJSUqKSlRW1tbXJoDEDthw97R0aHbt28nohcAcRTxDboDBw6oq6tL9fX1ysnJCfk4t9stn88nn8+npflLIh0OQJQiCvvx48e1atUqFRcXa2xsTMeOHQv5WI/HI5fLJZfLpTsTdyNuFEB0Igr7+Pi4ZmZmZFmWPB6PSktDf4sngNQQUdidTufs71u3blVPT0/MGgIQH2Hn2RsbG7V+/Xrl5eVpaGhItbW1Wr9+vYqLi2VZlm7evKl9++zXAEd0pv838rdD9K47Zf+AdREf+v+F/l54SZq2Qn8z/Q/Gvma774o//S/b+tRHH9nW8aiw/4p27tz52LaTJ0/GpRkA8cPbZQFDEHbAEIQdMARhBwxB2AFD8BHXeaCoZtC2/uVb+0PWvvFap+2+u/Iu2dZffca2HNY/TTpD1v6zIt9235mPRqMbHI/gyg4YgrADhiDsgCEIO2AIwg4YgrADhiDsgCGYZ58HpicmbOtfqg5dH3zGfqL8dEeZbf3VAvt5+L+69RXb+r8d+3rIWs7If9jui9jiyg4YgrADhiDsgCEIO2AIwg4YgrADhiDsgCGYZ1/gMr7gsK3/uOBfbOvj0/dt6+d/9Ee29ZyfMJeeKriyA4Yg7IAhCDtgCMIOGIKwA4Yg7IAhCDtgCObZF4DMZYUhay/981BUx9587C9s686fvBvV8ZE4Ya/shYWFunjxoq5du6aenh4dPHhQkpSbmyuv16u+vj55vV7l5OTEu1cAUQgb9qmpKVVVVenll1/Wq6++qv3796uoqEg1NTVqb2/XmjVr1N7erpqamkT0CyBCYcMeCATk9/slSffu3VNvb68KCgpUUVGhhoYGSVJDQ4O2bNkS10YBROepXrMvX75cJSUlunz5shwOhwKBgKSH/yE4HHO/B9vtdmvv3r2SpKX5S6JsF0Cknvhu/OLFi9XU1KRDhw5pcnLysbplWXPu5/F45HK55HK5dGfibuSdAojKE4U9MzNTTU1NOnPmjJqbmyVJwWBQTufDFTqdTqfGx8fj1yWAqD3R0/j6+nr19vaqrq5udltra6sqKyt19OhRVVZWqqWlJW5Nwt6NQ6Gn3lodrbb7dn46ZVv/4s//27Y+Y1tFKgkb9rKyMu3atUtXr16dvVF3+PBhHTlyROfOndOePXs0ODiobdu2xb1ZAJELG/ZLly4pLS1tztqGDRti3hCA+ODtsoAhCDtgCMIOGIKwA4Yg7IAh+IjrPJD+7LO29W99/b2QtbszH9vu+/r3/sy2ntbVaVvH/MGVHTAEYQcMQdgBQxB2wBCEHTAEYQcMQdgBQzDPPg9Mf/V3bet1X/jHkLWxaftPnKdd6oykJcxDXNkBQxB2wBCEHTAEYQcMQdgBQxB2wBCEHTAE8+zzQEbnB7b1L//77pC1Tat7wxz9kwg6wnzElR0wBGEHDEHYAUMQdsAQhB0wBGEHDEHYAUOEnWcvLCzU6dOn5XA4ZFmWTpw4oTfffFO1tbVyu92amJiQ9HAZ57a2trg3bKKZ+/dt61/a2RmyZj9DD5OEDfvU1JSqqqrk9/uVnZ2t9957TxcuXJAk1dXV6dixY3FvEkD0woY9EAgoEAhIku7du6fe3l4VFBTEvTEAsfVUr9mXL1+ukpISXb58WZJ04MABdXV1qb6+Xjk5OXPu43a75fP55PP5tDR/SdQNA4jME4d98eLFampq0qFDhzQ5Oanjx49r1apVKi4u1tjYWMin8x6PRy6XSy6XS3cm7sascQBP54nCnpmZqaamJp05c0bNzc2SpPHxcc3MzMiyLHk8HpWWlsa1UQDReaKw19fXq7e3V3V1dbPbnE7n7O9bt25VT09P7LsDEDNhb9CVlZVp165dunr1qvx+v6SH02w7duxQcXGxLMvSzZs3tW/fvrg3CyByYcN+6dIlpaWlPbadOXVgfuEddIAhCDtgCMIOGIKwA4Yg7IAhCDtgCMIOGIKwA4Yg7IAhCDtgCMIOGIKwA4Yg7IAhCDtgiDRJVqIGGx8f1+Dg4OzfeXl5unXrVqKGfyqp2luq9iXRW6Ri2dvy5cv1wgsvhKxbyfrx+XxJG3u+9paqfdFb6vfG03jAEIQdMERSw37ixIlkDm8rVXtL1b4keotUonpL6A06AMnD03jAEIQdMERSwr5p0yZdv35dH3zwgaqrq5PRQkgDAwOz35Hv8/mS2kt9fb2CwaC6u7tnt+Xm5srr9aqvr09erzfkGnvJ6K22tlbDw8Py+/3y+/0qLy9PSm+FhYW6ePGirl27pp6eHh08eFBS8s9dqL4Sed4SOqeYnp5u9ff3WytXrrSysrKszs5Oq6ioKOlznb/+GRgYsJ5//vmk9yHJWrdunVVSUmJ1d3fPbjt69KhVXV1tSbKqq6utI0eOpExvtbW1VlVVVdLPm9PptEpKSixJVnZ2tnXjxg2rqKgo6ecuVF+JOm8Jv7KXlpaqv79fAwMDevDggc6ePauKiopEtzEvdHR06Pbt249sq6ioUENDgySpoaFBW7ZsSUJnc/eWKgKBwOzqRb+9zHiyz12ovhIl4WEvKCjQ0NDQ7N/Dw8Mptd67ZVnyer26cuWK3G53stt5jMPhUCAQkPTwH4/D4UhyR496kmW8E+m3lxlPpXMXyfLn0eIG3WesXbtWr7zyisrLy7V//36tW7cu2S3Zsiwr2S3MetJlvBPls8uMf1ayzl2ky59HK+FhHxkZ0bJly2b/Liws1MjISKLbCGl0dFSSNDExoebm5pRbijoYDM6uoOt0OjU+Pp7kjn4jlZbxnmuZ8VQ4d8lc/jzhYff5fFq9erVWrFihrKwsbd++Xa2trYluY06LFi1Sdnb27O8bN25MuaWoW1tbVVlZKUmqrKxUS0tLkjv6jVRaxnuuZcZT4dwle/nzhN8tLS8vt27cuGH19/dbhw8fTvrd21//rFy50urs7LQ6Ozutnp6epPfW2NhojY6OWp9++qk1NDRk7d6923ruueesd955x+rr67MuXLhg5ebmpkxvp0+ftq5evWp1dXVZLS0tltPpTEpvZWVllmVZVldXl+X3+y2/32+Vl5cn/dyF6itR5423ywKG4AYdYAjCDhiCsAOGIOyAIQg7YAjCDhiCsAOG+D/oquGAFgctUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Re-run this cell to check out\n",
    "# different numbers from the test dataset!\n",
    "m = np.random.randint(1, 1000)\n",
    "\n",
    "img = dataset2[m][0]\n",
    "lbl = dataset2[m][1]\n",
    "\n",
    "plt.imshow(img[0])\n",
    "with torch.no_grad():\n",
    "    out = model.forward(img.view(img.size(0), -1)).float()\n",
    "\n",
    "print(f\"Correct label: {lbl}\")\n",
    "nums = [j for j in range(10)]\n",
    "\n",
    "print(f\"Prediction: {nums[np.argmax(out)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "72c6172d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction score: 0.98 (9809 out of 10000)\n"
     ]
    }
   ],
   "source": [
    "correct_score = 0\n",
    "total = len(dataset2)\n",
    "nums = [j for j in range(10)]\n",
    "\n",
    "for m in range(total):\n",
    "    with torch.no_grad():\n",
    "        img = dataset2[m][0]\n",
    "        lbl = dataset2[m][1]\n",
    "        out = model.forward(img.view(img.size(0), -1)).float()\n",
    "        prediction = nums[np.argmax(out)]\n",
    "        if prediction == lbl:\n",
    "            correct_score += 1\n",
    "            \n",
    "print(f\"Prediction score: {correct_score / total:.2f} ({correct_score} out of {total})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dd03a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The score of 98% correct answers is pretty impressive, if you ask me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef7247",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrap-up\n",
    "- **ML:** data-driven procedures.\n",
    "\n",
    "- We discussed three fundamental types of models:\n",
    "  - Linear Regression (wine prices),\n",
    "  - Logistic Regression (Framingham Risk Score),\n",
    "  - Neural Networks (Image recognition thing)\n",
    "  \n",
    "- Mostly, we define a \"loss\" and minimize it with respect to model parameters,\n",
    "- It's important to pick a good model for the problem at hand\n",
    "- NNs are quite powerful (even the simple ones we looked into in the course!), ...\n",
    "- ... but *interpretability* might be an issue.\n",
    "- usually, there are convenient libraries to run any given (more or less standard) type of models. So that you wouldn't need to take derivatives by hand :)\n",
    "- **a lot** of resources online (Coursera / EdX), Kaggle, blogs, etc. -- `README` file for this course contains a few links to start with..."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "rise": {
   "enable_chalkboard": true,
   "progress": true,
   "scroll": true,
   "theme": "night",
   "transition": "convex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
